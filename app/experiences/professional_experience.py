prof_exp = """[
    {
        "company": "RelationalAI",
        "position": "Machine Learning Engineer",
        "duration": "SEPTEMBER 2025 - PRESENT",
        "hardSkills": [
            { "title": "python", "description": "data pipelines, ml tooling" },
            { "title": "snowflake", "description": "knowledge-graph coprocessor, analytics" },
            { "title": "docker", "description": "" },
            { "title": "github actions", "description": "ci/cd for ml and data services" },
            { "title": "langchain / llm tooling", "description": "" },
            { "title": "mlops", "description": "monitoring, deployment, observability" },
            { "title": "data quality", "description": "schema and lineage checks for GraphRAG" }
        ],
        "responsibilities": [
            "Own data quality for knowledge-graph and GraphRAG pipelines, ensuring robust schema and lineage checks",
            "Design and maintain MLOps and CI/CD processes for graph and LLM-based services",
            "Collaborate with researchers and product engineers to productionize graph algorithms and LLM workflows"
        ]
    },
    {
        "company": "Mario Software Solutions",
        "position": "Founder & Software Engineering Consultant",
        "duration": "NOVEMBER 2023 - PRESENT",
        "hardSkills": [
            { "title": "python", "description": "backend, data tooling" },
            { "title": "data engineering", "description": "etl, data pipelines" },
            { "title": "system architecture", "description": "" },
            { "title": "aws", "description": "" },
            { "title": "terraform", "description": "infrastructure as code for client environments" }
        ],
        "responsibilities": [
            "Provide consulting in system architecture, software development, and data engineering to fintech and enterprise clients",
            "Enable fintech clients to scale operations via big data automation and optimized ETL processes",
            "Support Disney and other clients with automation and system enhancements on data engineering workflows"
        ]
    },
    {
        "company": "The Walt Disney Company",
        "position": "Senior Software Engineer | QA Engineer",
        "duration": "APRIL 2024 - SEPTEMBER 2025",
        "hardSkills": [
            { "title": "python", "description": "selenium, pytest, behave" },
            { "title": "snowflake", "description": "" },
            { "title": "airflow", "description": "" },
            { "title": "athena", "description": "" },
            { "title": "spark", "description": "" },
            { "title": "aws", "description": "" },
            { "title": "tableau", "description": "" },
            { "title": "microstrategy", "description": "" },
            { "title": "azure devops", "description": "" }
        ],
        "responsibilities": [
            "Supported the BI Addressable Data Engineering team as a QA Engineer within the Engineering department",
            "Developed and maintained an automation framework to validate data pipelines from sources to final reports across Disney, Hulu, and Disney+",
            "Expanded regression test suites, achieving 100% of fields covered in critical pipelines and significantly reducing production defects",
            "Collaborated with project managers and developers to deliver key projects on time while enhancing data quality and reliability"
        ]
    },
    {
        "company": "Creditas",
        "position": "Senior Software Engineer | Data Engineer",
        "duration": "AUGUST 2022 - NOVEMBER 2023",
        "hardSkills": [
            { "title": "python", "description": "flask, pandas, pytest" },
            { "title": "javascript", "description": "react" },
            { "title": "terraform", "description": "iac on aws for people analytics workloads" },
            { "title": "aws", "description": "lambda, s3, sqs, rds" },
            { "title": "gcp", "description": "" },
            { "title": "circleci", "description": "ci/cd pipelines (legacy projects)" },
            { "title": "postgres", "description": "" },
            { "title": "sqs", "description": "" },
            { "title": "metabase", "description": "" },
            { "title": "kibana", "description": "" },
            { "title": "prometheus", "description": "" },
            { "title": "datadog", "description": "monitoring and observability" },
            { "title": "github actions", "description": "ci/cd for backend and etl services" }
        ],
        "responsibilities": [
            "Stakeholders management to create an efficient backlog for People Analytics projects",
            "Integrations between People fintech systems with ETL processes to centralize and expose data",
            "Automations to generate efficiency on People processes such as contracts, communications, and Jira flows",
            "Applied FinOps principles to reduce infrastructure costs on AWS",
            "Mentored juniors and interns, improving the teamâ€™s delivery and engineering practices",
            "Defined and implemented development practices that optimized workflows for the People Analytics team"
        ]
    },
    {
        "company": "BTG Pactual",
        "position": "Data Engineer",
        "duration": "JANUARY 2022 - AUGUST 2022",
        "hardSkills": [
            { "title": "python", "description": "fastapi, pandas, pytest, pyspark" },
            { "title": "javascript", "description": "react" },
            { "title": "AWS", "description": "cloudformation, sqs, s3, athena, glue, cloudwatch, ecr, ec2, lambdas" },
            { "title": "C#(.NET)", "description": "" },
            { "title": "azure devops", "description": "boards, pipelines" },
            { "title": "jenkins", "description": "" },
            { "title": "postgres", "description": "" },
            { "title": "dynamo", "description": "dynamodb" },
            { "title": "kafka", "description": "" }
        ],
        "responsibilities": [
            "Worked in a project at BTG Pactual, one of the biggest investment banks in LATAM, as a Software Engineer focused on Data Engineering",
            "Designed and implemented near real-time big data auditing pipelines processing millions of transactions within minutes",
            "Built a cross-project solution to segment and map operational costs, serving financial, operations, and planning areas",
            "Leveraged AWS services (SQS, S3, Athena, Glue, CloudWatch, Lambdas, etc.) and Kafka to support ETL processes"
        ]
    },
    {
        "company": "Avantia",
        "position": "Software Developer",
        "duration": "JANUARY 2021 - JANUARY 2022",
        "hardSkills": [
            { "title": "python", "description": "opencv, tornado" },
            { "title": "typescript", "description": "angular, redux" },
            { "title": "aws", "description": "" },
            { "title": "azure devops", "description": "" },
            { "title": "postgres", "description": "" },
            { "title": "grey log", "description": "" }
        ],
        "responsibilities": [
            "Developed and maintained video monitoring systems to manage Artificial Intelligence services signals focused on security",
            "Helped create and maintain systems to watch and manage video/audio streams with AI alerts",
            "Optimized one of the core APIs response time by more than 50%, improving capacity and user experience",
            "Applied FinOps and basic data engineering techniques to reduce storage costs for video data"
        ]
    },
    {
        "company": "Euromercantil",
        "position": "IT Manager | Software Engineer | Data Engineer",
        "duration": "JUNE 2019 - JANUARY 2021",
        "hardSkills": [
            { "title": "python", "description": "pandas, selenium" },
            { "title": "php", "description": "laravel" },
            { "title": "javascript", "description": "vuejs" },
            { "title": "digital ocean", "description": "" },
            { "title": "postgres", "description": "" }
        ],
        "responsibilities": [
            "Started as a salesman and finished as IT manager in this fintech startup",
            "Planned the architecture change from monolith to microservices for internal systems",
            "Managed a 3 person team to build CRM, ERP, and auditing systems",
            "Led development of an ERP in PHP-Laravel and a Python-Pandas auditing system to improve financial accuracy",
            "Automated customer plan management, contributing to around 40% growth by streamlining processes"
        ]
    },
    {
        "company": "VTB Solutions",
        "position": "Software Developer (Intern)",
        "duration": "FEBRUARY 2019 - JUNE 2019",
        "hardSkills": [
            { "title": "C#", "description": ".NET" },
            { "title": "Power BI", "description": "" },
            { "title": "MongoDB", "description": "" }
        ],
        "responsibilities": [
            "Worked in a software factory to build ERP and CRM systems for several clients",
            "Used C#, .NET, and Power BI to deliver reporting and management features"
        ]
    },
    {
        "company": "Bisa Web",
        "position": "Intern Software Developer",
        "duration": "FEBRUARY 2017 - JANUARY 2018",
        "hardSkills": [
            { "title": "PHP", "description": "Laravel, Zend3, CodeIgniter" },
            { "title": "MySQL", "description": "" },
            { "title": "XAMPP", "description": "" },
            { "title": "javascript", "description": "" },
            { "title": "html5+css", "description": "" }
        ],
        "responsibilities": [
            "Software Developer in a company that managed specific taxes from organizations",
            "Built ERP systems with data analysis using PHP frameworks and MySQL"
        ]
    },
    {
        "company": "Universidade Federal de Pernambuco",
        "position": "AI Researcher",
        "duration": "JUNE 2016 - MAY 2017",
        "hardSkills": [
            { "title": "python", "description": "machine learning, web crawling" },
            { "title": "nlp", "description": "sentiment analysis" }
        ],
        "responsibilities": [
            "Researched cryptocurrency forecasts based on sentiment analysis of Reddit comments",
            "Used machine learning techniques, web crawlers, and sentiment analysis to build predictive models"
        ]
    }
]"""
